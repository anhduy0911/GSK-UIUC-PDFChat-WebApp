CHUNK_SIZE: 1024
CHUNK_OVERLAP: 64
MAX_HIST_LEN: 5

CACHE_DIR: '/scratch/bcgd/duyan2/.cache'
# EMBEDDINGS_MODEL: 'BAAI/bge-large-en'
EMBEDDINGS_MODEL: 'hkunlp/instructor-xl'
LLM_MODEL: 'anhduy0911/LLM-IE-Healthcare'
TOKENIZER: 'meta-llama/Meta-Llama-3-70B-Instruct'
# LLM_MODEL: 'TheBloke/Llama-2-13B-chat-GGUF'
GGUF_FILE: 'llama-2-13b-chat.Q4_K_M.gguf'